{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Penentuan Kelas Untuk Klasifikasi Faktor Kecelakaan Pesawat**\n",
        "\n",
        "## Nama Kelompok\n",
        "\n",
        "1.   Haarisah Yustika Putri Al-Jufri\n",
        "2.   Ony Novianti\n",
        "3.   Reynaldi Fakhri Pratama\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Jw8W43gsI6Gb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C_XQPcbYg5v",
        "outputId": "fbefc104-e6d1-4372-a066-849f55414292"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD4lO-MGYzKY",
        "outputId": "ba0cf1c6-f1a1-447f-e260-eab9f7ff4bdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upYG4ubf49Th",
        "outputId": "a720fc6b-3a90-41b1-ad4f-5aafceae0365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.10/dist-packages (0.0.post5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FbAvKN2aq3i"
      },
      "outputs": [],
      "source": [
        "# Import PySpark modules\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "from pyspark.ml.clustering import KMeans\n",
        "\n",
        "# Inisialisasi SparkSession\n",
        "spark = SparkSession.builder.appName(\"FlightAccidentStopWordsRemoval\").getOrCreate()\n",
        "\n",
        "# Load Data\n",
        "data = spark.read.csv(\"/content/drive/MyDrive/Airplane_Crashes_and_Fatalities_Since_1908.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Hapus Baris Kosong\n",
        "data = data.na.drop(subset=['Summary'])\n",
        "\n",
        "# Hapus karakter tambahan seperti , . spasi\n",
        "data = data.withColumn(\"Summary\", regexp_replace(data[\"Summary\"], \"[\\.,]\", \"\"))\n",
        "\n",
        "# Tokenize\n",
        "tokenizer = Tokenizer(inputCol=\"Summary\", outputCol=\"tokens\")\n",
        "data = tokenizer.transform(data)\n",
        "\n",
        "# Hilangkan stop word\n",
        "stopwords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
        "stopwords_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\", stopWords=stopwords)\n",
        "data = stopwords_remover.transform(data)\n",
        "\n",
        "# Hasil data\n",
        "# data.select(\"Summary\", \"filtered_tokens\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tampil Kolom\n",
        "# data.printSchema()\n"
      ],
      "metadata": {
        "id": "3S75N2b6splh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Jumlah baris data\n",
        "data.count()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCFd8MYrD1iP",
        "outputId": "82d5fa92-f73d-4f1a-ef62-cc6b950494cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4878"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gabungkan hasil token-token menjadi satu\n",
        "teks = [row[0] for row in data.select(\"filtered_tokens\").collect()]\n",
        "\n",
        "teks_gabung = [' '.join(dokumen) for dokumen in teks]\n",
        "\n",
        "# print(teks_gabung)\n"
      ],
      "metadata": {
        "id": "6uerzLFZFAE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "\n",
        "# Membuat objek TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Menghitung nilai TF-IDF\n",
        "tfidf_matrix = vectorizer.fit_transform(teks_gabung)\n",
        "\n",
        "# Mendapatkan daftar fitur\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "# Menampilkan hasil TF-IDF\n",
        "# top_k = 3\n",
        "# for i, row in enumerate(tfidf_matrix.toarray()):\n",
        "#     print(\"Dokumen\", i+1)\n",
        "#     top_indices = np.argsort(row)[::-1][:top_k]\n",
        "#     for index in top_indices:\n",
        "#         print(feature_names[index])\n",
        "#     print()\n"
      ],
      "metadata": {
        "id": "S3K2v2OoEVFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Memanfaatkan Model LDA Untuk Penentuan Topik"
      ],
      "metadata": {
        "id": "RWPv4F9N1ehU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim import corpora, models, matutils\n",
        "\n",
        "# Membuat corpus dari representasi TF-IDF\n",
        "corpus = matutils.Sparse2Corpus(tfidf_matrix.T)\n",
        "\n",
        "# Membangun kamus (dictionary)\n",
        "dictionary = corpora.Dictionary.from_corpus(corpus, id2word=dict(enumerate(feature_names)))\n",
        "\n",
        "# Melatih model LDA\n",
        "num_topics = 9  # Jumlah topik yang diinginkan\n",
        "lda_model = models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n",
        "\n",
        "# Menampilkan topik dan kata-kata kunci terkait\n",
        "topics = lda_model.show_topics(num_topics=num_topics, num_words=5)\n",
        "for topic in topics:\n",
        "    print(topic)\n",
        "\n",
        "# Menyematkan dokumen ke dalam topik\n",
        "document = \"Contoh dokumen yang ingin disematkan ke dalam topik\"\n",
        "bow_vector = dictionary.doc2bow(document.lower().split())\n",
        "doc_topics = lda_model.get_document_topics(bow_vector)\n",
        "for topic in doc_topics:\n",
        "    print(topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Yr2b1_C1ymK",
        "outputId": "a2c5712b-5b6a-499d-a82b-c1b507cece65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.013*\"helicopter\" + 0.008*\"rebels\" + 0.006*\"crashed\" + 0.006*\"shot\" + 0.006*\"rotor\"')\n",
            "(1, '0.009*\"crashed\" + 0.009*\"plane\" + 0.007*\"aircraft\" + 0.007*\"taking\" + 0.007*\"shortly\"')\n",
            "(2, '0.016*\"crashed\" + 0.011*\"takeoff\" + 0.009*\"mountain\" + 0.007*\"poor\" + 0.006*\"weather\"')\n",
            "(3, '0.015*\"approach\" + 0.015*\"plane\" + 0.013*\"crashed\" + 0.012*\"cargo\" + 0.011*\"runway\"')\n",
            "(4, '0.018*\"route\" + 0.018*\"en\" + 0.014*\"crashed\" + 0.010*\"plane\" + 0.006*\"cargo\"')\n",
            "(5, '0.012*\"crashed\" + 0.011*\"plane\" + 0.008*\"aircraft\" + 0.006*\"flight\" + 0.005*\"taking\"')\n",
            "(6, '0.009*\"plane\" + 0.009*\"crashed\" + 0.009*\"landing\" + 0.008*\"pilot\" + 0.008*\"aircraft\"')\n",
            "(7, '0.009*\"crashed\" + 0.009*\"flight\" + 0.008*\"pilot\" + 0.008*\"plane\" + 0.008*\"aircraft\"')\n",
            "(8, '0.010*\"crashed\" + 0.009*\"mountain\" + 0.009*\"taking\" + 0.008*\"aircraft\" + 0.008*\"plane\"')\n",
            "(0, 0.11111111)\n",
            "(1, 0.11111111)\n",
            "(2, 0.11111111)\n",
            "(3, 0.11111111)\n",
            "(4, 0.11111111)\n",
            "(5, 0.11111111)\n",
            "(6, 0.11111111)\n",
            "(7, 0.11111111)\n",
            "(8, 0.11111111)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coherence_model = CoherenceModel(model=lda_model, texts=teks, dictionary=dictionary, coherence='c_v')\n",
        "coherence_score = coherence_model.get_coherence()\n",
        "\n",
        "# Hasil coherence score\n",
        "print(\"Coherence Score:\", coherence_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elutXCR54i9n",
        "outputId": "e1008485-f29e-4c7d-e912-9d091c1b838e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence Score: 0.3672366124986783\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}